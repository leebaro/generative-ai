{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# 기존 pythonpath 제거\n",
    "if '/Users/frodo/Documents/project/git/mint/src/composer/dags' in sys.path:\n",
    "    sys.path.remove('/Users/frodo/Documents/project/git/mint/src/composer/dags')\n",
    "\n",
    "# pythonpath 초기화 \n",
    "# sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frodo/Documents/project/generative-ai/.venv/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8afc45f1a2341a6a8f35870bc9a2159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62760bc7159e497f81f7b1bcaeafbc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef2dd8e15654f9d86957ac8372eb791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d748878991f64c93932a3a7178dd1a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f318d003d773430fa8296d16ae47a666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/744 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15da8e9697524fa4a662dcd785cc1b1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219d86ded9464324bab6cacea16e118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/585 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d706526c548748bd9cb68114bfab5e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7671d079c924ccaaf3501b799cc09ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00bd7576da4412c9e68c5ec8b776e5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/156 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/frodo/Documents/project/generative-ai/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de152ad0a16f4e6f848303e298e8fbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 한 남자가 파스타를 먹는다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "한 남자가 음식을 먹는다. (Score: 0.5742)\n",
      "한 남자가 빵 한 조각을 먹는다. (Score: 0.4833)\n",
      "한 남자가 말을 탄다. (Score: 0.1337)\n",
      "치타 한 마리가 먹이 뒤에서 달리고 있다. (Score: 0.1249)\n",
      "한 남자가 담으로 싸인 땅에서 백마를 타고 있다. (Score: 0.1028)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "원숭이 한 마리가 드럼을 연주한다. (Score: 0.6619)\n",
      "한 여자가 바이올린을 연주한다. (Score: 0.2921)\n",
      "치타 한 마리가 먹이 뒤에서 달리고 있다. (Score: 0.2271)\n",
      "한 남자가 담으로 싸인 땅에서 백마를 타고 있다. (Score: 0.1968)\n",
      "한 남자가 음식을 먹는다. (Score: 0.1248)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 치타가 들판을 가로 질러 먹이를 쫓는다.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "치타 한 마리가 먹이 뒤에서 달리고 있다. (Score: 0.7968)\n",
      "원숭이 한 마리가 드럼을 연주한다. (Score: 0.2194)\n",
      "한 남자가 담으로 싸인 땅에서 백마를 타고 있다. (Score: 0.1424)\n",
      "한 남자가 음식을 먹는다. (Score: 0.1308)\n",
      "한 남자가 빵 한 조각을 먹는다. (Score: 0.0911)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "embedder = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['한 남자가 음식을 먹는다.',\n",
    " '한 남자가 빵 한 조각을 먹는다.',\n",
    " '그 여자가 아이를 돌본다.',\n",
    " '한 남자가 말을 탄다.',\n",
    " '한 여자가 바이올린을 연주한다.',\n",
    " '두 남자가 수레를 숲 속으로 밀었다.',\n",
    " '한 남자가 담으로 싸인 땅에서 백마를 타고 있다.',\n",
    " '원숭이 한 마리가 드럼을 연주한다.',\n",
    " '치타 한 마리가 먹이 뒤에서 달리고 있다.']\n",
    "\n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['한 남자가 파스타를 먹는다.',\n",
    "  '고릴라 의상을 입은 누군가가 드럼을 연주하고 있다.',\n",
    "  '치타가 들판을 가로 질러 먹이를 쫓는다.']\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    " query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    " cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    " cos_scores = cos_scores.cpu()\n",
    "\n",
    " #We use np.argpartition, to only partially sort the top_k results\n",
    " top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    " print(\"\\n\\n======================\\n\\n\")\n",
    " print(\"Query:\", query)\n",
    " print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    " for idx in top_results[0:top_k]:\n",
    "  print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
